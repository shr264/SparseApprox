{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;\red25\green25\blue25;
}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa240

\f0\fs32 \cf0 \expnd0\expndtw0\kerning0
The goal of this project is to look at various optimization algorithms in sparse approximation focussing on the basis pursuit denoting problem/lasso regression. The first part of the talk will briefly introduce sub gradient algorithms before going on to discuss ISTA/FISTA and ADMM algorithms. We discuss convergence rates and properties and generate our own data to explore these numerically. Finally, we adapt these methods to sparse approximation for Gaussian Graphical Models.
\fs24 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720

\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The second part of the talk will discuss the \cf4 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Message Passing Algorithm. \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 It is one of the linear programming (LP) methods to estimate sparse vectors. It improves on the LP methods by using belief propagation theory in graphical models. It is unlike the other linear methods which are very expensive when you need to recover very huge number of unknown variables with\'a0thousands of constraints. By following the steps of message passing algorithm we can\'a0find the approximate solution of the lasso problem. This algorithm is called\'a0Approximate Message algorithm (AMS). We introduce these algorithms and their performance by showing simulation results.}